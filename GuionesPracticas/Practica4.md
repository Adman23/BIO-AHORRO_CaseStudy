
## PRÁCTICA 4: EVALUACIÓN A/B Testing

Diseño Interfaces de Usuario 

Nº Sesiones: 2    

  

## Objetivo:

  
El objetivo de esta práctica es evaluar la usabilidad del prototipo mediante combinación de dos técnicas: A/B test y el cuestionario SUS (System Usability Scale). Esto permitirá evaluar el rendimiento comparado, usando dos alternativas de diseño que además se utilizará como método de co-evaluación de las prácticas de clase. Es decir, la técnica A/B testing se puede emplear para medir dos versiones de un mismo prototipo, o dos prototipos para un producto muy similar. El cuestionario SUS es el método más utilizado para medir la percepción subjetiva de usabilidad con un enfoque basado en aspectos emocionales (sensaciones). Usaremos el resultado de SUS (una etiqueta y un número entre 0 y 100) como base del A/B testing, si bien podría usarse cualquier otra métrica para realizar la comparativa.



## Planteamiento:

  

Vamos a partir de dos diseños de web (nuestra propuesta  A y otra práctica de otro compañero de clase elegida al azar denominada B). Vamos a seleccionar un conjunto de usuarios que actuarán como usuarios de estas dos prácticas (A y B), y a continuación, éstos deberán rellenar un cuestionario de usabilidad (encuesta SUS). Se hará una valoración de cuál es la mejor opción a partir de los datos recogidos.  

  

Resuma los hallazgos del A/B testing y del checklist de usabilidad en un documento de Informe de Usabilidad de la práctica B (máximo 3 páginas)  para el equipo B que concluya con la evaluación de usabilidad de la práctica del equipo compañero. 

  

Es muy importante que se suba el fichero al repositorio de DIU (CARPETA P4)  de modo que el equipo B pueda acceder a este informe. Por lo mismo, la evaluación de la práctica 3 de su equipo se localizará en el repositorio de los compañeros. 

  
## Descripción de la práctica:

  

Se realizará un estudio PRÁCTICO del interfaz de usuario en base a un grupo de usuarios. Para ello, esta práctica se divide en los siguientes puntos:

**1. [ASSIGNMENT]** Asignación de caso B. En clase de prácticas se asignará la práctica para co-evaluar. Esta práctica estará accesible desde un enlace Web (fork realizado a [https://github.com/mgea/D](https://github.com/mgea/DIU19)IU), Los repositorios están en [https://github.com/mgea/DIU/blob/master/P4/proyectos.md](https://github.com/mgea/DIU/blob/master/P4/proyectos.md) y las asignaciones en[https://github.com/mgea/DIU/blob/master/P4/Asignacion_ABtesting.pdf](https://github.com/mgea/DIU/blob/master/P4/Asignacion_ABtesting.pdf)   de modo que se podrá evaluar de forma online.

  
**2. [ROLE PLAY]** Usando personas ficticias.  Se escogen 4 personas de forma aleatoria aplicando role playing como evaluadores del prototipo A (2 valoraciones) y del prototipo asignado B (2 usuarios).  Posteriormente encuentre un usuario que se ajuste a dicho rol (un familiar, un compañero, o usted mismo simulando las necesidades o expectativas de dicha persona).

  

|   |   |   |
|---|---|---|
|![](https://lh7-qw.googleusercontent.com/docsz/AD_4nXc1R9hZrERSGFFRsQpCZ5szEUmQAMZrtSrajJybDr6yoOxOcJW67miMrEez3rMd8TxIFoXMzQ-cX9MYojd4JEVwS0CrpjaEQ5HgZPaM4NZQYYGz-AOt28hrqVC3tRxI4fwSqWmxqcTdnXhdjMbD-YzPanN6?key=wYRmjAVkiVNxrzJY5Mv_Vg)|![](https://lh7-qw.googleusercontent.com/docsz/AD_4nXfCxjQLvwREM0uqLN0YOzUN236bn9gOiqLl_JYGec3LlvIa1lIHY-lQ_vPGfn1idVxPcXUUB_OSo1LfqOeGSsW-bK1URfFzv4QO8L8iEPvtMFTLWwZs6GAbx8MfVheDC6Xkxkxqufae2yu1KEAISJd0cGI?key=wYRmjAVkiVNxrzJY5Mv_Vg)|![](https://lh7-qw.googleusercontent.com/docsz/AD_4nXduU7NkX9cK3jaIXmuGdfdUa_sADmp5KB7xjIndrONVL0x-ArpNReayatWm7woMc0fizUKe9r7BPzaC0mem-9wMry9_l57vhTNG2QdcS9oH4ZjKO1SwNyZSWfGf-oyxxxK4l36Lqq6q118HAM2faSIZsNqY?key=wYRmjAVkiVNxrzJY5Mv_Vg)|

  
Tras la tirada de dados, determine las necesidades que el usuario #id debe tener y que simule el rol marcado por los dados. Describa dichas necesidades con respecto a esa APP (caso A/B). Finalmente, resume dichos datos en una tabla: 

  

|   |   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|---|
|#id. usuario|Sexo/edad|Ocupación|Experiencia internet|Plataforma|Perfil cubierto|TEST|SUS score|
||||[Bajo, <br><br>Intermedio,<br><br>Avanzado]|Windows/<br><br>Mac/<br><br>Linux/<br><br>Phone/App|Resultado de la tirada de datos: Tipo, Actividad, Emoción|[A \| B]||

  **3. [eye tracking]** Técnicas de benchmarking para evaluar si están bien diseñadas las páginas. Para ello, usaremos Gaze Recorder (o similar) para crear el experimento que consistirá en introducir las imágenes (del prototipo) a evaluar, reclutar los usuarios y realizar la prueba de in situ o remota (se puede enviar link para hacerla sin supervisión). Se deben dar unas mínimas instrucciones al usuario de lo que debe hacer en cada página/imagen. Pueden ser tareas supervisadas de atención (por ejemplo: imagen 1 identifica cómo hacer una reserva, dónde está ubicado el local, etc.) o bien de exploración (p.e. mira la imagen/web y concéntrate en lo que más te llama la atención). Identificar al menos UN áreas de interés (AOI) por boceto que deben reconocerse por el usuario. Se aconseja dar un tiempo entre 4-6” por cada imagen

  

Haremos 2 test por cada caso y analizaremos los heat map en busca de diferencias significativas entre cómo se había diseñado la tarea y los mapas de calor de los sujetos. También se debe analizar los puntos de interés (AOI) que no han sido observados. Una forma sencilla de realizar este análisis es añadir un usuario experto (del equipo de diseño) y 2 usuarios objetivo, de modo que podamos comprobar diferencias entre ellos.  

  
  

|   |   |
|---|---|
|![](https://lh7-qw.googleusercontent.com/docsz/AD_4nXe38xXenEIMF9vqrU_BR8udArONhKqRUVDs0erKeNbJfrV6XQLZ5d-0xtMU0c5AGnqy786rtuZGNA__LhkbtAPj6ZCdyw-wRkiHANBakSvAWIidjm4sfeiQYISVv6oZROPI0dYD7lSGs41r39OmIQ6wrQHe?key=wYRmjAVkiVNxrzJY5Mv_Vg)<br><br>heatmap|![](https://lh7-qw.googleusercontent.com/docsz/AD_4nXcTQiIKu7qtNrhNzEUy9Sr4EwigImKGxumgXz-svYeMsQ1rDILkpe9lkxIR_JDxwXK0tvUfrmAAjme76VCGPdUcpLbD6fdu5bUG4fpYIVtbmWpHLewIXDebO0byizjHkxRn0eET03esRS1ti1RFxZ3mBfn_?key=wYRmjAVkiVNxrzJY5Mv_Vg)<br><br>  <br><br>Áreas de Interés (AoI)|

  
  
  

**4. [SUS QUESTIONNAIRE]** System Usability Scale Test (SUS). Cada usuario completará el cuestionario SUS para la aplicación asignada. Es un test de percepción que no funciona como cualquier otro cuestionario. Siga las instrucciones para el cálculo del SUS score y comente en el informe la  preferencia de A sobre B o viceversa.

  

Cómo usar la escala SUS e interpretar los resultados (pasar a escala linguística):

[http://usabilitygeek.com/how-to-use-the-system-usability-scale-sus-to-evaluate-the-usability-of-your-website/](http://usabilitygeek.com/how-to-use-the-system-usability-scale-sus-to-evaluate-the-usability-of-your-website/)

  

En el material complementario de la asignatura se encuentra el Excel que calcula SUS score a partir de las siguientes preguntas:

  
  

|   |   |   |   |   |   |   |
|---|---|---|---|---|---|---|
||PREGUNTAS|1|2|3|4|5|
|1|Creo que me gustará visitar con frecuencia este website||||||
|2|Encontré el website innecesariamente complejo||||||
|3|Pensé que era fácil utilizar este website||||||
|4|Creo que necesitaría del apoyo de un experto para recorrer el website||||||
|5|Encontré las funciones del website bastante bien integradas||||||
|6|Pensé que había demasiada inconsistencia en el website||||||
|7|Imagino que la mayoría de las personas aprenderían muy rápidamente a utilizar el website||||||
|8|Encontré el website muy grande al recorrerlo||||||
|9|Me sentí muy confiado en el manejo del website||||||
|10|Necesito aprender muchas cosas antes de manejarse en el website||||||

  

Hay un formulario compartido Online (que se debe duplicar si se desea usar) en URL: [https://docs.google.com/forms/d/1CwTpZJ08Yn6BX7k_Q5SOOfdX8BZXDDo53QdiIUSJeiY/edit](https://docs.google.com/forms/d/1CwTpZJ08Yn6BX7k_Q5SOOfdX8BZXDDo53QdiIUSJeiY/edit) 

Tambien disponible en PDF: [http://www.measuringux.com/sus/SUS.pdf](http://www.measuringux.com/sus/SUS.pdf) 

En PRADO se encuentra además un EXCEL para los cálculos de 4 usuarios.  [Cuestionario SUS DIU](https://pradogrado.ugr.es/moodle/mod/resource/view.php?id=165778) 

  
  
  
**5. [USABILITY REPORT]** Evaluación de usabilidad de la aplicación B. Se creará un mini-informe con los datos obtenidos para la aplicación B del A/B testing y así como recomendaciones de mejoras. Detecta, cataloga y recomienda solución a cada problema de usabilidad que detectes, siguiendo por el ejemplo la siguiente estructura:

 ![](https://lh7-qw.googleusercontent.com/docsz/AD_4nXcFjC-zFxUibLv6UIptOr0RMHt3QaPoGvnsFvSUEjSd8cfC0tdsnjx9hG96OUPaeEozpxfzJFBm2qGmFK1U7B3eGGz97p95bz7vwQa9dJvL9s_14lixE0HGbtoNlAhdp9BSiH9SX2kg1gg-s5m6CnixCvUZ?key=wYRmjAVkiVNxrzJY5Mv_Vg)

  

Este año vamos a SIMPLIFICAR y se puede hacer el informe con la plantilla en MarkDown que podeis encontrar en: [https://github.com/mgea/DIU/blob/master/P4/Usability-Report24.md](https://github.com/mgea/DIU/blob/master/P4/Usability-Report24.md) 

  

     Más información: 

- 25 puntos clave de la usabilidad [https://boluda.com/tutorial/25-puntos-clave-de-la-usabilidad/](https://boluda.com/tutorial/25-puntos-clave-de-la-usabilidad/) 
    

  



## DOCUMENTACIÓN A ENTREGAR

  
Se debe entregar el proyecto en un fichero comprimido ZIP. 

  

- Datos identificativos  del equipo
- Entregables de la práctica: 
1. Usuarios ficticios + propuesta del proyecto de experimento  
2. Resultados del Eye Tracking 
3. Cuestionario SUS  + Conclusiones A/B test 
4. Usability Report (caso B) 
    
Práctica Obligatoria: 1 punto (máximo) sobre la nota de prácticas. Valoración: Aplicación de role playing para 4 usuarios de A/B testing (25%), cálculo de SUS (25%), informe de eye tracking (25%) e informe de usabilidad de práctica B (25%).

  

El fichero se llamará {nombre_equipo}_P4, donde grupo: {DIU1, DIU2, DIU3}  se debe además publicar en GITHUB los resultados. 

  

El informe de usabilidad de la práctica B: se requiere que este archivo esté público en vuestro Github. Este archivo utilizará el siguiente estilo de nombrado: 

  

P4_UsabReport_{practB}_doneby_{grupo}_{nombre_equipo}

