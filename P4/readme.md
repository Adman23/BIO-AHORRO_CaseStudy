# DIU - Practica 4, entregables

>>> Se publicará la [Asignacion_ABtesting](https://github.com/mgea/DIU/blob/master/P4/Asignacion_ABtesting.pdf)
>>> Se publicará la lista de grupos y los respectivos GitHub

Se dispone del Template de usability.gob (https://www.usability.gov/how-to-and-tools/resources/templates/report-template-usability-test.html) 

- Users. Elección y características de los usuarios reclutados
- Diseño de las pruebas
- Realización del Cuestionario SUS para usuarios y casos A y B.
- Tabla A/B Testing con resultados para A y B
- Eye Tracking para B
- Usability Report del Caso B, con toda la información recabada del caso B
- Conclusiones


## Users

- Los usuarios son principalmente amigos y conocidos a los que hemos podido compartir los casos. En total hemos conseguido 10 usuarios, 5
- para el caso A y 5 para el caso B.

- La práctica indicaba usar un grupo de clase pero aún no teníamos listos los test para el día se podía hacer.

| **Usuario**           | **Sexo / Edad** | **Ocupación**          | **Exp. TIC** | **Personalidad** | **Plataforma** | **Caso** |
| --------------------- | --------------- | ---------------------- | ------------ | ---------------- | -------------- | -------- |
| **Alicia**            | Mujer / 15–30   | Estudiante             | Baja         | Precavida        | Móvil          | A        |
| **Blanca**            | Mujer / 15–30   | Editora junior         | Baja         | Creativa         | Móvil          | A        |
| **Maje**              | Hombre / 45–60  | Estudiante             | Media        | Divertida        | Móvil          | A        |
| **Juan Manuel**       | Hombre / 15–30  | Vendedor Ecológico     | Alta         | Extrovertido     | Móvil          | A        |
| **Lorenzo**           | Hombre / 15–30  | Estudiante             | Alta         | Sociable         | Móvil          | A        |
| **Victoria**          | Mujer / 15–30   | Estudiante             | Baja         | Responsable      | Móvil          | B        |
| **Cayo**              | Hombre / 15–30  | Estudiante             | Media        | Inteligente      | Móvil          | B        |
| **Marco**             | Hombre / 15–30  | Estudiante             | Alta         | Racional         | Móvil          | B        |
| **Diego**             | Hombre / 15–30  | Estudiante de la calle | Media        | Solidario        | Móvil          | B        |
| **Inma**              | Mujer / 15–30   | Estudiante             | Media        | Sensible         | Móvil          | B        |


## Diseño de las pruebas

- Para el diseño de las pruebas hemos utilizado maze, figma para probar el prototipo y formularios de google para las preguntas del
- cuestionario SUS. Hemos indicado a los usuarios una serie de tareas que tendrían que realizar con los prototipos y luego les hemos
- hecho rellenar el cuestionario SUS.

- Para realizar el método A/B testing se han planteado una serie de preguntas de respuesta breve para los usuarios y más abajo se pueden
- ver las tablas que recogen estos resultados

Las tareas que deberán realizar los usuarios son las siguientes:
* Contactar: Verificar que se puede navegar correctamente a la página de contacto.
* Consultar Eventos: Comprobar que se accede a la sección de eventos y se muestra la información esperada.
* Información: Validar el acceso y visualización del contenido de la página de información.
* Cuenta: Confirmar el acceso a la página de cuenta y la visibilidad de los datos del usuario.
* Leer comentarios: Comprobar que se puede acceder a la página de comentarios y visualizar los mismos.

Las tareas que se han planteado para el test de usabilidad han sido seleccionadas porque representan acciones clave dentro de cualquier aplicación orientada a la gestión de eventos o interacción con el usuario. Además, son funcionalidades **comunes a ambas aplicaciones evaluadas**, lo que permite hacer una comparación objetiva y coherente entre ellas.

Estas tareas cubren aspectos fundamentales de la experiencia de usuario, como la navegación básica, el acceso a información relevante, la gestión de cuenta personal y la posibilidad de interactuar con contenido generado por otros usuarios (comentarios). Evaluarlas garantiza que se tiene una visión general del funcionamiento de la interfaz y de los posibles puntos de fricción que pueda encontrar el usuario al utilizar el sistema.

### Cuestionario SUS
----
### Cuestionario SUS - A:
![image](https://github.com/user-attachments/assets/85c09915-c779-4605-a51b-f232a8534820)

### Cuestionario SUS - B:
![image](https://github.com/user-attachments/assets/3297422f-ca12-40ba-ba0c-b7c118c3c09e)

### Valoración de los resultados

## Análisis detallado del cuestionario SUS

### Proyecto A

La puntuación media del cuestionario SUS en el proyecto A es de **82/100**, lo que entra en el **rango A** (usabilidad aceptable y alta). La mayoría de los usuarios se han mostrado satisfechos con la navegación y funcionalidad de la aplicación, aunque algunos han identificado áreas específicas a mejorar.

- **Alicia Herrezuelo** obtuvo un **SUS de 90**, con una experiencia muy positiva. Considera que la app es fácil de usar y se siente segura navegando por ella. Aun así, encontro la app un poco grande al recorrerla, lo que se podría mejorar.

- **Blanca Lanzarot** obtuvo una puntuación de **67.5**, que entra en el **rango C** (marginal). A pesar de completar la tarea, sus respuestas reflejan que la app podría resultarle algo confusa e inecesariamente compleja.

- **María Jesús Luque** puntuó con **70**, también en el rango C. Sus respuestas indican que pudo utilizar la app, pero percibió dificultades leves relacionadas con la complejidad. Además no es la demografía objetivo, ya que puntua con indiferencia la visita a este tipo de aplicaciones.

- **Juan Manuel Navarro** obtuvo **100**, la puntuación máxima. Este usuario no encontró ninguna dificultad y se sintió completamente cómodo, aunque por la rapidez en sus respuestas se sospecha que pudo no haber reflexionado del todo en cada ítem.

- **Lorenzo Herrero** consiguió una puntuación de **82.5**, dentro del rango A. Valora positivamente el diseño general y la facilidad de uso.

En resumen, aunque la media es alta, **la diferencia entre usuarios sugiere que algunas personas encuentran la aplicación compleja**, lo que debe ser tenido en cuenta para futuras mejoras.

**Media global: 82**  
**Evaluación global: A (aceptable)**

### Proyecto B

En el caso del proyecto B, la media obtenida en el cuestionario SUS fue de **84.5/100**, lo que también entra en el **rango A** (alta usabilidad). Sin embargo, se observa una mayor dispersión entre las valoraciones de los usuarios, lo que indica que la experiencia de uso puede variar más entre personas.

- **Victoria** obtuvo una puntuación de **90**, valorando muy positivamente la experiencia. Considera que es una app clara y fácil de usar.

- **Nicolás** otorgó **85 puntos**, lo que confirma una percepción general de buena usabilidad. Cree que la app es coherente, aunque podría mejorar en la integración de las funciones.

- **Marco** dio la puntuación máxima: **100**. Sin embargo, se detectó que respondió muy rápido y sin detenerse en cada pregunta, por lo que se considera que su respuesta puede ser menos representativa.

- **Diego** puntuó con **70**, lo que lo sitúa en el rango C (marginal). Este usuario tuvo dificultades con la navegación y detectó problemas con el manejo de la aplicación.

- **Inma Orzuelo** obtuvo **77.5**, dentro del rango B. Percibió la app como funcional, pero con detalles por mejorar, también siendo el manejo de la aplicación.

Aunque la media es alta, **varias opiniones encuentran aspectos de la aplicacion complejos de manejar**.

**Media global: 84.5**  
**Evaluación global: A (aceptable, con margen de mejora)**

### Imagen de referencia: Rango de interpretación SUS

![Interpretación SUS](https://github.com/user-attachments/assets/d59f3960-e905-4b76-b36f-cfd7593c4bc6)

### Conclusión comparativa

- El **proyecto A** presenta una experiencia robusta en cuanto a usabilidad, aunque algunos usuarios encontraron la información demasiado densa y los elementos visuales poco optimizados.
- El **proyecto B** se percibe como más intuitivo y ligero, pero necesita reforzar aspectos como el feedback tras acciones y añadir funciones clave (editar perfil, registro/inicio de sesión).

Ambos proyectos obtienen puntuaciones aceptables, pero muestran **diferencias cualitativas importantes** que deben ser consideradas si se busca optimizar la experiencia de usuario.

### A/B Testing
-----
## Método A/B Testing
Además del cuestionario SUS, se aplicó un test práctico basado en tareas clave para evaluar la experiencia de uso real de cada aplicación. Las tareas se realizaron con los mismos usuarios que participaron en el SUS, y se centraron en los siguientes objetivos:

### Tareas evaluadas

1. **Contactar**: Verificar que se puede navegar correctamente a la página de contacto.
2. **Consultar eventos**: Comprobar que se accede a la sección de eventos y se muestra la información esperada.
3. **Información**: Validar el acceso y visualización del contenido de la página de información.
4. **Cuenta**: Confirmar el acceso a la página de cuenta y la visibilidad de los datos del usuario.
5. **Leer comentarios**: Comprobar que se puede acceder a la página de comentarios y visualizar los mismos.

### Proyecto A

#### Usuarios: Alicia Herrezuelo, Blanca Lanzarot, María Jesús Luque, Juan Manuel Navarro, Lorenzo Herrero  
**Media SUS: 82 (Rango A - aceptable)**

Los usuarios completaron la mayoría de tareas, aunque se identificaron algunos puntos comunes de mejora: textos pequeños y una interfaz algo recargada visualmente. La navegación general fue correcta, pero menos fluida que en el otro proyecto.

### Proyecto B

#### Usuarios: Victoria, Nicolás, Marco, Diego, Inma Orzuelo  
**Media SUS: 84.5 (Rango A - aceptable)**

La mayoría de los usuarios consideraron la app clara, ligera e intuitiva. Las tareas se completaron correctamente, aunque se detectaron algunas carencias: falta de feedback al interactuar, ausencia de funcionalidades como registro o edición de datos, y contraste visual mejorable. A pesar de ello, la navegación resultó más directa y sencilla.

### Conclusión del A/B Testing

Ambas aplicaciones permiten completar las tareas previstas, pero presentan diferencias clave en la experiencia de usuario.

- **Proyecto B** obtiene una **mejor puntuación en el cuestionario SUS (84.5 frente a 82)** y una **navegación más intuitiva y ligera**. A pesar de algunas carencias funcionales (como la ausencia de inicio de sesión o edición de cuenta), los usuarios encuentran la app más accesible y comprensible en su estructura.

- **Proyecto A** presenta una interfaz más completa en cuanto a contenido, pero también más cargada y menos clara visualmente. Algunos usuarios encontraron dificultades relacionadas con el tamaño del texto, la sobrecarga informativa y la falta de edición de perfil.

En resumen, aunque **ambos proyectos son funcionales y alcanzan una evaluación positiva**, el **proyecto B destaca por su simplicidad, claridad y mejor puntuación global en usabilidad**, lo que lo posiciona como el prototipo con mejor experiencia de usuario según los datos recogidos.

### Aplicación del método Eye Tracking 
![Método UX](img/eye-tracking.png)
----

![image](https://github.com/user-attachments/assets/0e2cff68-0a9e-433e-a33d-db7d2de36356)
<br>
Para realizar el análisis de eye-tracking utilizamos la herramienta **GazeRecorder**. En ella cargamos la imágen correspondiente al home page. Esto nos permitió evaluar visualmente qué elementos captaban la atención de los usuarios en las secciones clave de la página principal.

### Usability Report de B
![Método UX](img/usability-report.png) 
-----
Se ha aplicado un método UX mixto compuesto por:

- **Evaluación heurística mediante tareas concretas**: los usuarios debían completar acciones típicas dentro del prototipo de la app.
- **Cuestionario SUS (System Usability Scale)** para evaluar la percepción global de la experiencia.
- **Eye-tracking experimental** mediante WebGazer, para detectar áreas de atención en la interfaz principal.

La evaluación fue realizada por el equipo **DIU1_FernandoAdam** sobre el proyecto **La Tertulia**.


### Evaluación de Usabilidad

#### Descripción del proyecto evaluado

**La Tertulia** es una app para un bar cultural que combina gastronomía con eventos como charlas, recitales y conciertos. La app permite ver eventos, comentar, participar en escenarios abiertos, conocer la historia del bar y gestionar el perfil de usuario.


### Resultados de la prueba

#### Debilidades detectadas

| Debilidad detectada | Valoración UX del equipo |
|---------------------|--------------------------|
| **No se pueden editar los datos del usuario** | Limita la personalización del perfil. Se sugiere añadir opción de edición básica. |
| **El calendario no es claro** | No se explican los días destacados ni se puede interactuar con ellos. Podría confundirse con un elemento decorativo. |
| **Etiquetas como “HOY”, “JUEVES”, “MAÑANA” no son interactivas** | Esto corta la fluidez de navegación. Sería útil que llevaran al evento del día correspondiente. |
| **Términos arbitrarios como “JUEVES” generan confusión** | No queda claro su significado. Requiere contexto o funcionalidad. |
| **Falta de feedback visual al pulsar botones** | Los botones “Participa” o “Enviar comentario” no ofrecen confirmación de acción. Esto puede crear incertidumbre en el usuario. |
| **El icono de perfil tiene bajo contraste y es poco visible** | Dificulta el acceso rápido a funciones personales, especialmente en pantallas pequeñas. |


#### Resultados de cuestionario SUS

| Usuario | Edad | Sexo | SUS Score |
|--------|------|------|-----------|
| Victoria | 15–30 | Mujer | 90 |
| Nicolás | 15–30 | Hombre | 85 |
| Marco | 15–30 | Hombre | 100 |
| Diego | 15–30 | Hombre | 70 |
| Inma | 15–30 | Mujer | 77.5 |

> **Promedio estimado (sin Marco): ~80.6**, considerado **bueno** pero con margen de mejora.

#### Eye-tracking

- La atención se concentra en la **zona superior** (imágenes y cabecera).
- El **icono de perfil apenas es visualizado**: bajo contraste y tamaño reducido.
- Se ignoran zonas interactivas no evidentes como etiquetas de fecha.

### Valoración del equipo

La app presenta un diseño visual atractivo y una navegación general intuitiva. El contenido está bien organizado y refleja con acierto el espíritu del bar. Sin embargo, hay aspectos de la interfaz que pueden generar confusión y reducir la fluidez de uso.

La metodología empleada (tareas + SUS + eye-tracking) ha sido clave para descubrir errores no evidentes en la fase de diseño. Ha permitido observar el comportamiento real de los usuarios y extraer conclusiones relevantes para iteraciones futuras.

### Recomendaciones de mejora

- Aumentar la visibilidad y contraste del botón de perfil.
- Hacer interactivos los elementos del calendario y etiquetas como “HOY”.
- Añadir opciones para editar los datos del usuario desde el perfil.
- Incluir feedback visual tras acciones como comentar o participar.
- Mejorar la semántica de los términos utilizados en la interfaz (como “JUEVES”).

### Enlace al proyecto evaluado

[Repositorio del proyecto La Tertulia – GitHub](https://github.com/sofiiaglez11/DIU2-string?tab=readme-ov-file)














